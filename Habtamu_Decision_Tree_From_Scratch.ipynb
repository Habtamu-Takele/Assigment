{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944ba2a5",
   "metadata": {},
   "source": [
    "# From-Scratch Implementation\n",
    "\n",
    "We’ll need two classes:\n",
    "\n",
    "    Node – implements a single node of a decision tree\n",
    "    DecisionTree – implements the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661a01aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[CustomDecisionTree | 2022-06-05 15:02:30] \u001b[0m200 splitters proposed\n",
      "\t\t[0 1 4]\n",
      "\t(0, -0.8772999747193541)\n",
      "\t\t\t[ 2 13 14]\n",
      "\t\t(0, 0.8264860325015251)\n",
      "\t\t\t[10 11 12]\n",
      "(1, -0.4257500339183419)\n",
      "\t\t[5 7 9]\n",
      "\t(0, -0.635333143020312)\n",
      "\t\t\t[ 3  6  8 17]\n",
      "\t\t(0, 0.2599310000151684)\n",
      "\t\t\t[15 16 18 19]\n",
      "\n",
      "Max depth:  1  score:  0.885\n",
      "Max depth:  2  score:  0.89\n",
      "Max depth:  5  score:  0.915\n",
      "Max depth:  10  score:  0.975\n",
      "Max depth:  15  score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.validation import check_X_y\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "class habteTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.data = None\n",
    "\n",
    "    def __str__(self, level=0):\n",
    "        ret = \"\\t\"*level+repr(self.data)+\"\\n\"\n",
    "        for child in [self.left, self.right]:\n",
    "            if child is not None:\n",
    "                ret += child.__str__(level+1)\n",
    "        return ret\n",
    "\n",
    "    def habtecustom_print(self, f1, f2, level=0):\n",
    "        if self.left is None:\n",
    "            ret = \"\\t\"*level+f2(self.data)+\"\\n\"\n",
    "        else:\n",
    "            ret = \"\\t\"*level+f1(self.data)+\"\\n\"\n",
    "\n",
    "        if self.right is not None:\n",
    "            ret = self.right.custom_print(f1, f2, level+1) + ret\n",
    "        if self.left is not None:\n",
    "            ret += self.left.custom_print(f1, f2, level+1)\n",
    "\n",
    "        return ret\n",
    "    \n",
    "class habteCustomDecisionTree:\n",
    "\n",
    "    def __init__(self, penalty_function, max_depth=3, min_sample_size=3, max_thresholds=10,\n",
    "                 verbose=False):\n",
    "        self._max_depth = max_depth\n",
    "        self._min_sample_size = min_sample_size\n",
    "        self._max_thresholds = max_thresholds\n",
    "        self._penalty_function = penalty_function\n",
    "        self._verbose = verbose\n",
    "        self._y = None\n",
    "\n",
    "    def fit(self, X, y, indices=None):\n",
    "        check_X_y(X, y)\n",
    "        self._y = y\n",
    "        self._tree = Tree()\n",
    "        splitters = self._build_splitters(X)\n",
    "\n",
    "        if indices is None:\n",
    "            indices = np.arange(X.shape[0])\n",
    "\n",
    "        if self._verbose:\n",
    "            self._print(\"{} splitters proposed\".format(len(splitters)))\n",
    "\n",
    "        self._train(self._tree, indices, 0, splitters, 0, X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array(\n",
    "            list(map(lambda row: self._predict_one(row), X)), dtype=int)\n",
    "\n",
    "    def _penalty(self, indices, y):\n",
    "        predicted = [np.bincount(y[indices]).argmax()] * len(indices)\n",
    "        return self._penalty_function(y[indices], predicted)\n",
    "\n",
    "    def _print(self, input_str):\n",
    "        time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(bcolors.CYAN + \"[CustomDecisionTree | \" +\n",
    "              time + \"] \" + bcolors.ENDC + str(input_str))\n",
    "\n",
    "    def _find_indices_for_row(self, row):\n",
    "        return self._traverse_trained_tree(self._tree, row)\n",
    "\n",
    "    def _predict_one(self, row):\n",
    "        indices = self._find_indices_for_row(row)\n",
    "        return np.bincount(self._y[indices]).argmax()\n",
    "\n",
    "    def _traverse_trained_tree(self, tree, row):\n",
    "        if tree.left is None:\n",
    "            return tree.data\n",
    "        else:\n",
    "            index, threshold = tree.data\n",
    "            if row[index] > threshold:\n",
    "                return self._traverse_trained_tree(tree.left, row)\n",
    "            else:\n",
    "                return self._traverse_trained_tree(tree.right, row)\n",
    "\n",
    "    def _build_splitters(self, X):\n",
    "        splitters = []\n",
    "\n",
    "        for i, column in enumerate(X.T):\n",
    "            sorted_unique_values = np.sort(np.unique(column))\n",
    "            thresholds = (\n",
    "                sorted_unique_values[:-1] + sorted_unique_values[1:]) / 2\n",
    "            n_thresholds = len(thresholds)\n",
    "\n",
    "            if len(thresholds) > self._max_thresholds:\n",
    "                thresholds = thresholds[[round(\n",
    "                    i*n_thresholds / self._max_thresholds) for i in range(self._max_thresholds)]]\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                splitters.append((i, threshold))\n",
    "\n",
    "        return splitters\n",
    "\n",
    "    def _split(self, splitter, indices, X):\n",
    "        index, threshold = splitter\n",
    "        mask = X[indices, index] > threshold\n",
    "        return indices[mask], indices[~mask]\n",
    "\n",
    "    def _splitter_score(self, splitter, indices, X, y):\n",
    "        indices_left, indices_right = self._split(splitter, indices, X)\n",
    "        n_left, n_right = len(indices_left), len(indices_right)\n",
    "\n",
    "        if n_left < self._min_sample_size:\n",
    "            return -100000\n",
    "\n",
    "        if n_right < self._min_sample_size:\n",
    "            return -100000\n",
    "\n",
    "        return (n_left * self._penalty(indices_left, y) +\n",
    "                n_right * self._penalty(indices_right, y)) / \\\n",
    "            (n_left + n_right)\n",
    "\n",
    "    def _train(self, tree, indices, depth, splitters, current_score, X, y):\n",
    "        if depth >= self._max_depth:\n",
    "            tree.data = indices\n",
    "        else:\n",
    "            splitter_and_scores = list(\n",
    "                map(lambda ns: (ns, self._splitter_score(ns, indices, X, y)), splitters))\n",
    "            scores = list(map(lambda sp: sp[1], splitter_and_scores))\n",
    "            if len(scores) == 0:\n",
    "                tree.data = indices\n",
    "                return\n",
    "            max_score = max(scores)\n",
    "            max_index = scores.index(max_score)\n",
    "            non_trival_splitters_and_scores = list(\n",
    "                filter(lambda p: p[1] != -100000, splitter_and_scores))\n",
    "            non_trival_splitters = list(\n",
    "                map(lambda p: p[0], non_trival_splitters_and_scores))\n",
    "\n",
    "            best_splitter, best_score = splitter_and_scores[max_index]\n",
    "            indices_left, indices_right = self._split(\n",
    "                best_splitter, indices, X)\n",
    "\n",
    "            if len(indices_left) < self._min_sample_size or \\\n",
    "               len(indices_right) < self._min_sample_size:\n",
    "                tree.data = indices\n",
    "\n",
    "            else:\n",
    "                tree.data = best_splitter\n",
    "\n",
    "                tree.left = Tree()\n",
    "                tree.right = Tree()\n",
    "\n",
    "                self._train(tree.left, indices_left, depth + 1,\n",
    "                            non_trival_splitters, best_score, X, y)\n",
    "                self._train(tree.right, indices_right, depth + 1,\n",
    "                            non_trival_splitters, best_score, X, y)\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    X, y = make_classification(n_samples=20, shuffle=False, n_redundant=3)\n",
    "    cdt = habteCustomDecisionTree(accuracy_score, verbose=True)\n",
    "\n",
    "    cdt.fit(X, y)\n",
    "\n",
    "    print(cdt._tree.custom_print(str,str))\n",
    "\n",
    "    X, y = make_classification(n_samples=200, shuffle=False, n_redundant=3)\n",
    "    for max_depth in [1,2,5,10,15]:\n",
    "        cdt = habteCustomDecisionTree(accuracy_score, min_sample_size=1, max_depth=max_depth)\n",
    "        cdt.fit(X, y)\n",
    "        y_hat = cdt.predict(X)\n",
    "        score = accuracy_score(cdt.predict(X), y)\n",
    "        print(\"Max depth: \", max_depth, \" score: \", score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e189f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
